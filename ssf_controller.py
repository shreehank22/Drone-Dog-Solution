# -*- coding: utf-8 -*-
"""SSF_Controller.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QTbORQ8gJ-l0A8KF06uvAwr3OEBZufEH
"""

import rclpy
from rclpy.node import Node
from pynput import keyboard
import threading
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import cv2.aruco as aruco
import numpy as np
from dronekit import connect, VehicleMode
from pymavlink import mavutil
import time
import math


P_GAIN_X = 0.5
P_GAIN_Y = 0.5
P_GAIN_Z = 0.3
MAX_VELOCITY = 1.0


ID_TO_FIND = 72
MARKER_SIZE = 0.2
NP_CAMERA_MATRIX = np.array([
    [467.74270306499267, 0.0, 320.5],
    [0.0, 467.74270306499267, 240.5],
    [0.0, 0.0, 1.0]
], dtype=np.float32)
NP_DIST_COEFF = np.zeros((5,), dtype=np.float32)
ARUCO_DICT = aruco.getPredefinedDictionary(aruco.DICT_ARUCO_ORIGINAL)
ARUCO_PARAMS = aruco.DetectorParameters()
HORIZONTAL_RES = 640
VERTICAL_RES = 480

HORIZONTAL_FOV = 68.75 * (math.pi / 180)
VERTICAL_FOV = 54.32 * (math.pi / 180)

TAKEOFF_HEIGHT = 3.0
MANUAL_VELOCITY = 0.5
CENTER_TOLERANCE = 0.05
LAND_ALTITUDE_THRESHOLD = 0.3

class DroneController(Node):
    def __init__(self):
        super().__init__('drone_controller')
        self.bridge = CvBridge()
        self.vehicle = None
        self.is_flying = False
        self.target_altitude = 0.0
        self.last_process_time = time.time()
        self.process_interval = 0.1
        self.manual_keys = set()
        self.publisher_processed = self.create_publisher(Image, '/processed/image', 10)


        gst_str = (
            "udpsrc address=0.0.0.0 port=5600 ! "
            "application/x-rtp,encoding-name=H264,payload=96 ! "
            "rtph264depay ! h264parse ! avdec_h264 ! videoconvert ! "
            "appsink drop=1 sync=false"
        )
        self.cap = cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)
        if not self.cap.isOpened():
            self.get_logger().error("Could not open camera!")
            raise RuntimeError("Could not open GStreamer pipeline!")
        self.get_logger().info("Camera is on.")

        self.connect_vehicle()
        if self.vehicle:
            self.get_logger().info("Drone connected.")

        listener = keyboard.Listener(on_press=self.on_press, on_release=self.on_release)
        listener.start()


        self.timer = self.create_timer(0.05, self.timer_callback)

    def connect_vehicle(self):

        self.get_logger().info('Connecting drone...')
        try:
            self.vehicle = connect('udp:127.0.0.1:14550', wait_ready=True, timeout=60)
            self.vehicle.parameters['PLND_ENABLED'] = 1
            self.vehicle.parameters['PLND_TYPE'] = 1
            self.vehicle.parameters['PLND_EST_TYPE'] = 0
            self.vehicle.parameters['LAND_SPEED'] = 30
            self.get_logger().info('Drone connected and PLND parameters set.')
        except Exception as e:
            self.get_logger().error(f"Drone connection failed: {e}")
            self.vehicle = None


    def arm_and_takeoff(self, altitude):

        self.get_logger().info("Drone is being armed")
        while not self.vehicle.is_armable:
            time.sleep(1)

        self.vehicle.mode = VehicleMode("GUIDED")
        self.vehicle.armed = True

        while not self.vehicle.armed:
            self.get_logger().info("It is expected to be arm...")
            time.sleep(1)

        self.get_logger().info(f"Engines started, Takeoff begins at {altitude} m")
        self.vehicle.simple_takeoff(altitude)

        while True:
            alt = self.vehicle.location.global_relative_frame.alt
            if abs(alt - altitude) <= 0.5:
                self.is_flying = True
                self.target_altitude = alt
                self.get_logger().info("Takeoff completed!")
                break
            time.sleep(0.5)

    def send_ned_velocity(self, vx, vy, vz):

        if not self.vehicle or self.vehicle.mode.name != 'GUIDED':
             return
        vx = np.clip(vx, -MAX_VELOCITY, MAX_VELOCITY)
        vy = np.clip(vy, -MAX_VELOCITY, MAX_VELOCITY)
        vz = np.clip(vz, -MAX_VELOCITY, MAX_VELOCITY)

        msg = self.vehicle.message_factory.set_position_target_local_ned_encode(
            0, 0, 0,
            mavutil.mavlink.MAV_FRAME_BODY_NED,
            0b0000111111000111,
            0, 0, 0,
            vx, vy, vz,
            0, 0, 0,
            0, 0
        )
        self.vehicle.send_mavlink(msg)

    def stop_movement(self):
        self.send_ned_velocity(0, 0, 0)

    def land_drone(self):

        self.vehicle.mode = VehicleMode("LAND")
        self.is_flying = False
        self.get_logger().info("Drone lands!")


    def on_press(self, key):

        try:
            if key.char in ['w','a','s','d','e']:
                self.manual_keys.add(key.char)
            if key.char == 'f' and not self.vehicle.armed:
                threading.Thread(target=self.arm_and_takeoff, args=(TAKEOFF_HEIGHT,)).start()
            elif key.char == 'q' and self.is_flying:
                self.land_drone()
        except AttributeError:
            pass

    def on_release(self, key):

        try:
            if key.char in self.manual_keys:
                self.manual_keys.remove(key.char)
            if not self.manual_keys:
                self.stop_movement()
        except AttributeError:
            pass



    def timer_callback(self):
        if not self.vehicle or not self.is_flying:
             self.stop_movement()
             return

        if self.manual_keys:
            vx, vy, vz = 0.0, 0.0, 0.0
            if 'w' in self.manual_keys: vx += MANUAL_VELOCITY
            if 's' in self.manual_keys: vx -= MANUAL_VELOCITY
            if 'd' in self.manual_keys: vy += MANUAL_VELOCITY
            if 'a' in self.manual_keys: vy -= MANUAL_VELOCITY
            if 'e' in self.manual_keys: vz += MANUAL_VELOCITY
            self.send_ned_velocity(vx, vy, vz)

            ret, frame = self.cap.read()
            if ret:
                msg_processed = self.bridge.cv2_to_imgmsg(frame, encoding='bgr8')
                self.publisher_processed.publish(msg_processed)
                cv2.imshow("DRONE CAM", frame)

            return


        current_time = time.time()
        if current_time - self.last_process_time < self.process_interval:
            return
        self.last_process_time = current_time

        ret, frame = self.cap.read()
        if not ret:
            self.get_logger().warning("Frame could not be received!")
            return

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)


        vx, vy, vz = 0.0, 0.0, 0.0
        marker_found = False
        tvec_display = "NO MARKER"

        if ids is not None:
            for i, marker_id in enumerate(ids.flatten()):
                if marker_id == ID_TO_FIND:
                    marker_found = True
                    marker_corners = corners[i]
                    rvec, tvec, _ = aruco.estimatePoseSingleMarkers(
                        marker_corners, MARKER_SIZE, NP_CAMERA_MATRIX, NP_DIST_COEFF)
                    rvec, tvec = rvec[0,0,:], tvec[0,0,:]

                    tvec_display = f'X={tvec[0]:.2f} Y={tvec[1]:.2f} Z={tvec[2]:.2f}'
                    aruco.drawDetectedMarkers(frame, [marker_corners])
                    cv2.drawFrameAxes(frame, NP_CAMERA_MATRIX, NP_DIST_COEFF, rvec, tvec, 0.1)


                    vy = tvec[0] * P_GAIN_Y

                    vz = -tvec[1] * P_GAIN_Z


                    depth_error = tvec[2] - LAND_ALTITUDE_THRESHOLD

                    vx = -depth_error * P_GAIN_X


                    is_centered = abs(tvec[0]) < CENTER_TOLERANCE and abs(tvec[1]) < CENTER_TOLERANCE
                    is_close_enough = tvec[2] < (LAND_ALTITUDE_THRESHOLD + 0.1)

                    if is_centered and is_close_enough and self.vehicle.mode.name != 'LAND':
                        self.get_logger().info("Centered and close enough. Initiating LAND mode.")
                        self.land_drone()

                    if self.vehicle.mode.name == 'GUIDED':
                        self.send_ned_velocity(vx, vy, vz)

                    break
        if not marker_found and self.vehicle.mode.name == 'GUIDED':
            self.stop_movement()
            tvec_display = "Searching..."


        cv2.putText(frame, tvec_display, (10,50),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)

        msg_processed = self.bridge.cv2_to_imgmsg(frame, encoding='bgr8')
        self.publisher_processed.publish(msg_processed)
        cv2.imshow("DRONE CAM", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            self.get_logger().info("The program is terminated with the 'q' key.")
            rclpy.shutdown()

def main(args=None):

    rclpy.init(args=args)
    node = DroneController()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        if node.vehicle:
            node.vehicle.close()
        node.destroy_node()
        rclpy.shutdown()

if __name__=='__main__':
    main()